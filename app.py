import os
import re
import json
import time
import random
import requests
from fastapi import FastAPI, Request

app = FastAPI()

# =========================
# Environment Variables
# =========================
LINE_CHANNEL_ACCESS_TOKEN = os.getenv("LINE_CHANNEL_ACCESS_TOKEN", "").strip()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "").strip()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini").strip()
PA_SQL_RUNNER_URL = os.getenv("PA_SQL_RUNNER_URL", "").strip()

# =========================
# Safety rails
# =========================
# å…ˆæ”¾ä½ å·²é©—è­‰ OK çš„è¡¨ï¼›ä¹‹å¾Œæ”¹ view / gold table å†åŠ é€²ä¾†
ALLOWED_FROM = [
    "dbo.cqcr310",
]

BANNED_SQL = re.compile(r"\b(insert|update|delete|drop|alter|create|truncate|merge)\b", re.IGNORECASE)



# =========================
# Plant normalization
# =========================
PLANT_ALIAS = {
    "è¶Šå—": ["è¶Šå—", "vietnam", "VN", "vn", "è¶Šå» ", "è¶Šå—å» "],
    "æ˜†å±±": ["æ˜†å±±", "KS", "AK", "ks", "æ˜†å±±å» "],
    "å¢é”": ["å¢é”", "ZD", "zd", "å¢é”å» "],
}

# reverse map alias(lowered) -> cn
ALIAS_TO_CN = {}
for cn, aliases in PLANT_ALIAS.items():
    for a in aliases:
        ALIAS_TO_CN[a.strip().lower()] = cn


def normalize_plant_from_text(text: str) -> str | None:
    """Try find plant from user question text."""
    if not text:
        return None
    t = text.strip().lower()
    # exact alias match by containment
    for alias, cn in ALIAS_TO_CN.items():
        if alias and alias in t:
            return cn
    return None


def normalize_plant_value(raw: str) -> str | None:
    """Normalize a single plant value (from SQL literal) to CN."""
    if raw is None:
        return None
    v = str(raw).strip().strip('"').strip("'").strip()
    if not v:
        return None
    key = v.lower()
    key = key.replace("  ", " ").strip()
    key = key.replace("viet-nam", "vietnam").replace("viet nam", "viet nam")
    # direct match (cn values)
    if v in PLANT_ALIAS:
        return v
    # alias match
    if key in ALIAS_TO_CN:
        return ALIAS_TO_CN[key]
    return None


def enforce_plant_in_sql(sql: str, plant_cn: str | None) -> str:
    """
    Force Plant filter to use Chinese values in SQL.
    - If plant_cn provided (from user question), it overrides SQL's plant.
    - If SQL has Plant='Vietnam' etc, normalize to CN.
    - Supports "=" and "IN (...)"
    """
    if not sql:
        return sql

    original = sql

    # 1) Replace Plant = 'xxx'
    def repl_eq(m: re.Match):
        left = m.group(1)  # Plant or [Plant] etc (keep)
        quote = m.group(2)
        val = m.group(3)
        cn = plant_cn or normalize_plant_value(val) or val
        # SQL Server unicode literal
        return f"{left} = N'{cn}'"

    eq_pattern = re.compile(r"(\bPlant\b|\[Plant\]|\`Plant\`)\s*=\s*(['\"])([^'\"]+)\2", re.IGNORECASE)
    sql = eq_pattern.sub(repl_eq, sql)

    # 2) Replace Plant IN ('a','b',...)
    def repl_in(m: re.Match):
        left = m.group(1)
        inside = m.group(2)
        # split by comma, keep simple parsing
        parts = [p.strip() for p in inside.split(",")]
        new_vals = []
        for p in parts:
            pv = p.strip().strip("'").strip('"').strip()
            cn = plant_cn or normalize_plant_value(pv) or pv
            new_vals.append(f"N'{cn}'")
        return f"{left} IN ({', '.join(new_vals)})"

    in_pattern = re.compile(r"(\bPlant\b|\[Plant\]|\`Plant\`)\s+IN\s*\(([^)]+)\)", re.IGNORECASE)
    sql = in_pattern.sub(repl_in, sql)

    # 3) If user asked for a plant, but SQL has no plant filter -> inject it
    if plant_cn:
        has_plant_filter = re.search(r"(\bPlant\b|\[Plant\]|\`Plant\`)\s*(=|IN)\s*", sql, re.IGNORECASE) is not None
        if not has_plant_filter:
            # insert before GROUP BY / ORDER BY if exists, else append
            inject = f" Plant = N'{plant_cn}' "
            if re.search(r"\bWHERE\b", sql, re.IGNORECASE):
                # add AND before GROUP/ORDER
                sql = re.sub(r"\b(GROUP\s+BY|ORDER\s+BY)\b", rf"AND{inject}\n\1", sql, flags=re.IGNORECASE, count=1)
                if sql == original:
                    sql = sql.rstrip().rstrip(";") + f"\nAND{inject};"
            else:
                # add WHERE before GROUP/ORDER
                sql = re.sub(r"\b(GROUP\s+BY|ORDER\s+BY)\b", rf"WHERE{inject}\n\1", sql, flags=re.IGNORECASE, count=1)
                if sql == original:
                    sql = sql.rstrip().rstrip(";") + f"\nWHERE{inject};"

    if sql != original:
        print("SQL plant normalized.")
    return sql


# =========================
# Defect normalization
# =========================
# "ä¸è‰¯" (defect) includes "ç‰¹æ¡" (special acceptance) and "é©—é€€" (rejection).
# Per user: ä¸è‰¯=ç‰¹æ¡&é©—é€€, é©—é€€=åˆ¤é€€, ä¸è‰¯=NG
DEFECT_ALIAS = {
    "é©—é€€": ["é©—é€€", "åˆ¤é€€"],
    "ç‰¹æ¡": ["ç‰¹æ¡"],
    # Assuming 'å…æ”¶' is a valid value for accepted
    "å…æ”¶": ["å…æ”¶", "ok", "accept"],
}

# Special group alias for "defect" which maps to multiple values
DEFECT_GROUP_ALIAS = {
    "ä¸è‰¯": ["ä¸è‰¯", "ng", "ä¸è‰¯æ‰¹"],
}

# Reverse map for single aliases (lowered) -> canonical name
DEFECT_ALIAS_TO_CN = {}
for cn, aliases in DEFECT_ALIAS.items():
    for a in aliases:
        DEFECT_ALIAS_TO_CN[a.strip().lower()] = cn


def normalize_defect_from_text(text: str) -> list[str] | None:
    """Try find defect terms from user question text. Returns a list of canonical defect names."""
    if not text:
        return None
    t = text.strip().lower()

    # Check for group alias first, as it's more specific
    for group_alias in DEFECT_GROUP_ALIAS["ä¸è‰¯"]:
        if group_alias in t:
            return ["é©—é€€", "ç‰¹æ¡"]  # "ä¸è‰¯" means both rejected and special acceptance

    # Check for individual aliases
    found_defects = set()
    for alias, cn in DEFECT_ALIAS_TO_CN.items():
        if alias and alias in t:
            found_defects.add(cn)

    if found_defects:
        return list(found_defects)

    return None


# =========================
# Basic endpoints
# =========================
@app.get("/health")
def health():
    return {"ok": True}


@app.get("/")
def root():
    return {"ok": True, "service": "line-webhook"}


# =========================
# LINE APIs
# =========================
def line_reply(reply_token: str, text: str) -> None:
    """Reply immediately (replyToken is one-time-use)."""
    if not LINE_CHANNEL_ACCESS_TOKEN or not reply_token:
        print("Missing LINE_CHANNEL_ACCESS_TOKEN or reply_token")
        return

    url = "https://api.line.me/v2/bot/message/reply"
    headers = {
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}",
        "Content-Type": "application/json",
    }
    payload = {"replyToken": reply_token, "messages": [{"type": "text", "text": text[:5000]}]}
    resp = requests.post(url, headers=headers, json=payload, timeout=15)
    print("LINE reply:", resp.status_code, resp.text[:200])


def line_push(user_id: str, text: str) -> None:
    """Push message (for second message after replying)."""
    if not LINE_CHANNEL_ACCESS_TOKEN or not user_id:
        print("Missing LINE_CHANNEL_ACCESS_TOKEN or user_id")
        return

    url = "https://api.line.me/v2/bot/message/push"
    headers = {
        "Authorization": f"Bearer {LINE_CHANNEL_ACCESS_TOKEN}",
        "Content-Type": "application/json",
    }
    payload = {"to": user_id, "messages": [{"type": "text", "text": text[:5000]}]}
    resp = requests.post(url, headers=headers, json=payload, timeout=15)
    print("LINE push:", resp.status_code, resp.text[:200])


# =========================
# OpenAI (with retries)
# =========================
def call_openai(messages):
    if not OPENAI_API_KEY:
        raise RuntimeError("OPENAI_API_KEY not set (Zeabur Variables)")

    url = "https://api.openai.com/v1/chat/completions"
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": OPENAI_MODEL,
        "messages": messages,
        "temperature": 0.0,
        "max_tokens": 650,
    }

    # Retry for 429 / 5xx
    for attempt in range(5):
        r = requests.post(url, headers=headers, json=payload, timeout=60)

        if r.status_code == 429 or (500 <= r.status_code < 600):
            wait = (2 ** attempt) + random.uniform(0, 0.8)
            print(f"OpenAI retry {attempt+1}/5, status={r.status_code}, wait={wait:.1f}s, body={r.text[:120]}")
            time.sleep(wait)
            continue

        if r.status_code >= 400:
            raise RuntimeError(f"OpenAI error {r.status_code}: {r.text[:300]}")

        return r.json()["choices"][0]["message"]["content"]

    raise RuntimeError("OpenAI rate limited (429). Please try again later.")



# =========================
# NL -> SQL
# =========================
def strip_code_fence(s: str) -> str:
    s = s.strip()
    s = re.sub(r"^```[a-zA-Z0-9]*\s*", "", s)
    s = re.sub(r"\s*```$", "", s)
    return s.strip()


def generate_sql(question: str) -> str:
    system = (
        "ä½ æ˜¯ä¼æ¥­è³‡æ–™åº«çš„ SQL ç”¢ç”Ÿå™¨ã€‚"
        "åªè¼¸å‡ºä¸€æ®µå¯åŸ·è¡Œ SQLï¼ˆä¸è¦è§£é‡‹ã€ä¸è¦ markdownï¼‰ã€‚"
        "é™åˆ¶ï¼šåªå…è¨± SELECTã€‚"
        f"FROM åªèƒ½ä½¿ç”¨ä»¥ä¸‹ç™½åå–®ï¼š{', '.join(ALLOWED_FROM)}ã€‚"
        "è«‹ç‰¹åˆ¥æ³¨æ„ï¼š1) Plant æ¬„ä½æ˜¯ä¸­æ–‡ï¼ˆè¶Šå—/æ˜†å±±/å¢é”ï¼‰ã€‚ 2) Inspection_Result æ¬„ä½ä¹Ÿæ˜¯ä¸­æ–‡ï¼ˆåˆæ ¼/ç‰¹æ¡/é©—é€€ï¼‰ï¼Œå…¶ä¸­ã€Œä¸è‰¯ã€æˆ–ã€ŒNGã€ä»£è¡¨ Inspection_Result æ˜¯ 'ç‰¹æ¡' æˆ– 'é©—é€€'ã€‚"
        "è‹¥è¦è¿‘30å¤©ï¼Œè«‹ä½¿ç”¨ SQL Server èªæ³•ï¼šWHERE Inspection_Date >= DATEADD(day,-30, CAST(GETDATE() AS date))ã€‚"
        "æ¬„ä½å·²çŸ¥ï¼šPlant, Inspection_Date, Product_Number, Product_Name, Supplier_Short_Name, "
        "Inspection_Item_Defect_Cause, Submitted_Quantity, Defect_Quantity, Sample_Size, Inspection_Result, Receiving_Number, Remarkã€‚"
        "å¸¸è¦‹éœ€æ±‚ï¼šNGç‡=SUM(Defect_Quantity)/NULLIF(SUM(Submitted_Quantity),0)ã€‚"
        "è«‹å„ªå…ˆå›å‚³å¯ç”¨æ–¼ç®¡ç†è€…æŸ¥çœ‹çš„ Top N çµæœï¼ˆORDER BY ... DESCï¼‰ã€‚"
    )
    user = f"å•é¡Œï¼š{question}\nè«‹è¼¸å‡º SQLï¼š"
    sql = call_openai([{"role": "system", "content": system}, {"role": "user", "content": user}]).strip()
    sql = strip_code_fence(sql)
    return sql.strip().strip(";")


def validate_sql(sql: str) -> str:
    s = sql.strip().strip(";")
    if not s.lower().startswith("select"):
        raise ValueError("åªå…è¨± SELECT")
    if BANNED_SQL.search(s):
        raise ValueError("åµæ¸¬åˆ°ç¦æ­¢çš„ SQL é—œéµå­—")

    ok = any(re.search(rf"\bfrom\s+{re.escape(t)}\b", s, re.IGNORECASE) for t in ALLOWED_FROM)
    if not ok:
        raise ValueError(f"FROM ä¾†æºä¸åœ¨ç™½åå–®ï¼š{ALLOWED_FROM}")

    return s

def summarize_with_llm(question: str, sql: str, rows: list[dict]) -> str:
    """
    ç”¨ LLM æŠŠ SQL çµæœå¯«æˆè‡ªç„¶ä¸­æ–‡å›ç­”ï¼ˆé¿å…æ¨¡æ¿æ„Ÿï¼‰
    - åªé¤µå‰ N ç­†ï¼ˆé¿å… token å¤ªå¤§ï¼‰
    """
    # é¿å… rows å¤ªå¤§çˆ† tokenï¼šåªå–å‰ 15 ç­†
    preview_rows = rows[:15]

    system = (
        "ä½ æ˜¯ä¼æ¥­å…§éƒ¨å“è³ª/è£½é€ æ•¸æ“šåŠ©ç†ã€‚"
        "è«‹ç”¨è‡ªç„¶ã€å£èªä½†å°ˆæ¥­çš„ç¹é«”ä¸­æ–‡å›ç­”ã€‚"
        "å›ç­”è¦ï¼š1) å…ˆä¸€å¥è©±çµè«– 2) å†åˆ—å‡ºé‡é»æ•¸æ“š(æ¢åˆ—) 3) å¦‚æœ‰ä¸ç¢ºå®š(ä¾‹å¦‚æ¬„ä½ç¼ºå¤±/è³‡æ–™ä¸è¶³)è¦èªªæ˜ã€‚"
        "ä¸è¦æåˆ°ä½ æ˜¯AIï¼Œä¸è¦è²¼å‡ºSQLå…¨æ–‡ï¼Œé™¤éä½¿ç”¨è€…è¦æ±‚ã€‚"
        "æ•¸å­—ç›¡é‡åŠ ä¸Šå–®ä½/ç™¾åˆ†æ¯”ä¸¦å››æ¨äº”å…¥ã€‚"
        "è‹¥ rows å¾ˆå°‘æˆ–ç‚ºç©ºï¼Œè«‹ç›´æ¥èªªæŸ¥ä¸åˆ°è³‡æ–™ä¸¦çµ¦å¯èƒ½åŸå› ã€‚"
    )

    user = {
        "question": question,
        "sql_preview": sql[:600],        # ä¸è¦å¤ªé•·ï¼Œé¿å…å®ƒç…§æŠ„
        "rows_preview": preview_rows     # çµ¦å®ƒçœ‹è³‡æ–™
    }

    content = call_openai([
        {"role": "system", "content": system},
        {"role": "user", "content": json.dumps(user, ensure_ascii=False)}
    ])

    return content.strip()[:4500]



# =========================
# Call Power Automate SQL Runner
# =========================
def run_sql_via_pa(sql: str):
    if not PA_SQL_RUNNER_URL:
        raise RuntimeError("PA_SQL_RUNNER_URL not set (Zeabur Variables)")

    payload = {"sql": sql, "top": 50}
    print("Calling PA runner:", PA_SQL_RUNNER_URL[:80], "...")
    print("SQL:", sql[:220])

    r = requests.post(PA_SQL_RUNNER_URL, json=payload, timeout=90)
    print("PA runner status:", r.status_code, r.text[:200])

    if r.status_code >= 400:
        raise RuntimeError(f"PA runner error {r.status_code}: {r.text[:500]}")

    data = r.json()
    return data.get("rows", [])


# =========================
# Local summary (no 2nd OpenAI call)
# =========================
def summarize_locally(question: str, sql: str, rows) -> str:
    if not rows:
        return "æŸ¥ç„¡è³‡æ–™ï¼šå¯èƒ½æ˜¯ç¯©é¸æ¢ä»¶å¤ªåš´æ ¼æˆ–è¿‘30å¤©æ²’æœ‰è³‡æ–™ã€‚"

    def get_float(x):
        try:
            return float(x)
        except Exception:
            return None

    top = rows[:10]
    first = top[0]

    plant = first.get("plant") or first.get("Plant") or ""
    part_no = first.get("part_no") or first.get("Product_Number") or ""
    part_name = first.get("part_name") or first.get("Product_Name") or ""
    ng_rate = get_float(first.get("ng_rate") or first.get("NG_Rate") or first.get("ngRate"))

    lines = []
    if ng_rate is not None:
        lines.append(f"ğŸ“Œ è¿‘30å¤© NGç‡æœ€é«˜ï¼š{plant} / {part_no}ï¼ˆ{part_name}ï¼‰ï¼ŒNGç‡ç´„ {ng_rate*100:.2f}%")
    else:
        lines.append(f"ğŸ“Œ è¿‘30å¤©çµæœç¬¬ä¸€åï¼š{plant} / {part_no}ï¼ˆ{part_name}ï¼‰")

    lines.append("å‰10åå¦‚ä¸‹ï¼š")
    for i, r in enumerate(top, 1):
        p = r.get("plant") or r.get("Plant") or ""
        pn = r.get("part_no") or r.get("Product_Number") or ""
        pr = get_float(r.get("ng_rate") or r.get("NG_Rate") or r.get("ngRate"))
        if pr is not None:
            lines.append(f"{i}. {p} / {pn}  NGç‡ {pr*100:.2f}%")
        else:
            lines.append(f"{i}. {p} / {pn}")

    return "\n".join(lines)[:4500]


# ===== Dedup (POC: in-memory) =====
PROCESSED = {}  # key -> timestamp
DEDUP_TTL_SECONDS = 15 * 60  # 15 min

def _cleanup_processed(now: float):
    # æ¸…æ‰å¤ªèˆŠçš„ keyï¼Œé¿å…è¨˜æ†¶é«”ä¸€ç›´é•·
    old_keys = [k for k, ts in PROCESSED.items() if now - ts > DEDUP_TTL_SECONDS]
    for k in old_keys:
        PROCESSED.pop(k, None)

def is_duplicate(event_key: str) -> bool:
    now = time.time()
    _cleanup_processed(now)
    if event_key in PROCESSED:
        return True
    PROCESSED[event_key] = now
    return False



# =========================
# LINE Webhook
# =========================
@app.post("/line/webhook")
async def line_webhook(req: Request):
    body = await req.json()
    print("LINE webhook received:", json.dumps(body, ensure_ascii=False)[:600])
    print("OPENAI_API_KEY len:", len(OPENAI_API_KEY or ""))

    events = body.get("events", [])
    if not events:
        return {"ok": True}

    evt = events[0]

    # replyToken (one-time)
    reply_token = evt.get("replyToken") or evt.get("reply_token") or ""

    # userId for push
    source = evt.get("source") or {}
    user_id = source.get("userId") or evt.get("user_id") or ""

    # text
    msg = evt.get("message") or {}
    text = ""
    if isinstance(msg, dict):
        text = (msg.get("text") or "").strip()
    if not text:
        text = (evt.get("text") or "").strip()

    if not reply_token or not text:
        return {"ok": True}

    # å– message id ç•¶ dedup keyï¼ˆè‹¥æ²’æœ‰å°±ç”¨ replyToken + timestamp çµ„åˆï¼‰
    msg = evt.get("message") or {}
    msg_id = (msg.get("id") or "").strip()
    ts = str(evt.get("timestamp") or "")
    dedup_key = msg_id or f"{reply_token}:{ts}"

    if is_duplicate(dedup_key):
        print("Duplicate event, skip:", dedup_key)
        return {"ok": True}


    # 1) immediate reply
    line_reply(reply_token, "æ”¶åˆ°ï¼ŒæŸ¥è©¢ä¸­â€¦")

    try:
        sql = generate_sql(text)
        sql = validate_sql(sql)
        rows = run_sql_via_pa(sql)

        # local summary to avoid second OpenAI call (reduce 429 risk)
        # answer = summarize_locally(text, sql, rows)

        # Summarize answer with llm
        answer = summarize_with_llm(text, sql, rows)


        # 2) push result
        line_push(user_id, answer)

    except Exception as e:
        msg = str(e)
        if "rate limited" in msg.lower() or "429" in msg:
            line_push(user_id, "ç›®å‰ AI æœå‹™æš«æ™‚è¢«é™æµï¼ˆ429ï¼‰ï¼Œè«‹ 1~2 åˆ†é˜å¾Œå†è©¦ä¸€æ¬¡ã€‚")
        else:
            line_push(user_id, f"æŸ¥è©¢å¤±æ•—ï¼š{type(e).__name__}\n{msg[:350]}")

    return {"ok": True}
